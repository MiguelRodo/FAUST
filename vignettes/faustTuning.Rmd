---
title: "FAUST Tuning"
author: 
- Evan Greene
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{FAUST Tuning}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---
```{r setup, include = FALSE}
knitr::opts_chunk$set(
  comment = "#>",
  dpi = 300
)
```

# Introduction

This vignette provides information about the two main component functions of the `R` function <code style="color:skyblue">faust</code>: the functions `generateAnnotationThresholds` and `discoverPhenotypes`.
If you inspect the `R` source, you will see the <code style="color:skyblue">faust</code> function is a simple wrapper around these two functions.
These functions, in turn, orchestrate the two main phases of the `FAUST` analysis: marker scoring, selection, and threshold standardization, occurs in `generateAnnotationThresholds`; phenotype discovery then occurs in `discoverPhenotypes` once the standardized thresholds have been approved by the user.

We will discuss both phases in this vignette.

```{r libraries_and_sim, message = FALSE, echo=FALSE}
# load libraries and code to simulate data.
suppressPackageStartupMessages({
  library(mvtnorm)
  library(MASS)
  library(flowCore)
  library(flowWorkspace)
  library(ggplot2)
  library(cowplot)
  library(knitr)
  library(dplyr)
  library(tidyr)
  library(faust)
  library(ggridges)
})

Posdef <- function (n, ev = runif(n, 1, 2))
{
    #function written by Ravi Varadhan, from r-help mailing list
    #Thu Feb 7, 20:02:30 CET 2008
    #Generates a positive definine matrix of dimension n
    #ev bounds the variance by 2
    Z <- matrix(ncol=n, rnorm(n^2))
    decomp <- qr(Z)
    Q <- qr.Q(decomp)
    R <- qr.R(decomp)
    d <- diag(R)
    ph <- d / abs(d)
    O <- Q %*% diag(ph)
    Z <- t(O) %*% diag(ev) %*% O
    return(Z)
}

labelMeanVector <- function(meanVector) {
    baseStr <- paste0("V",seq(length(meanVector)))
    tokenStr <- rep("+",length(meanVector))
    tokenStr[which(meanVector==0)] <- "-"
    return(paste0(paste0(baseStr,tokenStr),collapse=""))
}

genClusterCentersWithLabels <- function(possibleCenterMat,
                                        nPop=5,
                                        seedVal=0)
{
    pcMat <- t(possibleCenterMat)
    allPops <- expand.grid(split(pcMat,rep(seq(nrow(pcMat)),ncol(pcMat))))
    if (nPop > nrow(allPops)) {
        print("Too many clusters relative to specMat/possibleCenterMat.")
        stop("Reduce number of clusters or increase possible mean vectors.")
    }
    clusterIndex <- sample(seq(nrow(allPops)),nPop)
    outMat <- allPops[clusterIndex,,drop=FALSE]
    outLab <- as.character(apply(outMat,1,labelMeanVector))
    outList <- list(fixedMeanMatrix=outMat,fixedLabelVector=outLab)
    return(outList)
}

getSimTrueCountMatrix <- function(truthList)
{
    uniqueNames <- c()
    for (i in seq(length(truthList))) {
        uniqueNames <- append(uniqueNames,names(truthList[[i]]))
    }
    uniqueNames <- sort(unique(uniqueNames))
    truthMat <- matrix(0,nrow=length(truthList),ncol=length(uniqueNames))
    colnames(truthMat) <- uniqueNames
    rownames(truthMat) <- names(truthList)
    for (i in seq(length(truthList))) {
        cv <- truthList[[i]]
        for (cName in colnames(truthMat)) {
            lookup <- which(names(cv) == cName)
            if (length(lookup)) {
                truthMat[i,cName] <- cv[lookup]
            }
        }
    }
    return(truthMat)
}

simSample <- function(sampleDim,
                      sampleSize,
                      transformationType,
                      mixtureType="gaussianOnly",
                      fixedMeanMatrix=NA,
                      fixedLabelVector=NA,
                      noiseDim=0,
                      probVecSample,
                      isKnockout=FALSE,
                      isSpikeIn=FALSE,
                      sRegime=0,
                      targetRanks=c(length(probVecSample)-1,length(probVecSample)),
                      hasBatchEffect=FALSE,
                      batchEffect=0
                      )
{
    numClusters <- nrow(fixedMeanMatrix)
    probVec <- probVecSample
    knockoutStatus <- "No knockout"
    if (isKnockout) {
        targetProbs <- sort(probVec)
        targetProb <- targetProbs[ceiling(length(targetProbs)/2)]
        targetLookup <- which(probVec == targetProb)
        modProbLookups <- setdiff(seq(length(probVec)),targetLookup)
        knockoutStatus <- fixedLabelVector[targetLookup]
        probVec[modProbLookups] <- (probVec[modProbLookups] + (targetProb/length(modProbLookups)))
        probVec[targetLookup] <- 0
    }
    if ((sRegime) && (isSpikeIn)) {
        currentSpikeMass <- probVec[targetRanks[2]]
        targetSpikeMass <- probVec[targetRanks[1]]
        massIncrement <- currentSpikeMass/(length(probVec)-1)
        probVec <- probVec + massIncrement
        probVec[targetRanks[2]] <- 0
        probVec <- probVec - (targetSpikeMass * probVec)
        probVec[targetRanks[2]] <- targetSpikeMass
        if (abs(sum(probVec) - 1) > 1e-9) {
            print(probVec)
            print(sum(probVec))
            print(abs(sum(probVec) - 1))
            stop("Error in probability reapportionment")
        }
        if (min(probVec) == probVec[targetRanks[2]]) {
            stop("Error in spiking in population")
        }
    }
    sampleSizeVec <- as.vector(t(rmultinom(1,sampleSize,probVec)))
    outData <- matrix(nrow=0,ncol=(sampleDim+noiseDim))
    outLabel <- c()
    for (clusterNumber in seq(numClusters)) {
        if (sampleSizeVec[clusterNumber] == 0) {
            next
        }
        currentMu <- as.numeric(fixedMeanMatrix[clusterNumber,,drop=TRUE])
        if (hasBatchEffect) {
            currentMu <- currentMu + batchEffect 
        }
        subjectShift <- round(rnorm(length(currentMu),mean=0,sd=(1/sqrt(2))))
        currentMu <- currentMu + subjectShift 
        currentLabel <- fixedLabelVector[clusterNumber]
        outLabel <- append(outLabel,rep(currentLabel,sampleSizeVec[clusterNumber]))
        currentSigma<- Posdef(sampleDim)
        if (mixtureType == "tPlusGauss") {
            if ((clusterNumber %% 2) == 0) {
                currentSample <- mvrnorm(sampleSizeVec[clusterNumber],mu=currentMu,Sigma=currentSigma)
            }
            else {
                currentSample <- rmvt(sampleSizeVec[clusterNumber],delta=currentMu,sigma=currentSigma,df=2)
            }
        }
        else if (mixtureType == "tOnly") {
            currentSample <- rmvt(sampleSizeVec[clusterNumber],delta=currentMu,sigma=currentSigma,df=2)
        }
        else  {
            currentSample <- mvrnorm(sampleSizeVec[clusterNumber],mu=currentMu,Sigma=currentSigma)
        }
        if (is.vector(currentSample)) {
            currentSample <- t(as.matrix(currentSample))
        }
        if (noiseDim > 0) {
            currentSigma<- Posdef(noiseDim)
            noiseSample <- mvrnorm(nrow(currentSample),mu=rep(5,noiseDim),Sigma=currentSigma)
            if (is.vector(noiseSample)) {
                noiseSample <- t(as.matrix(noiseSample))
            }
            currentSample <- cbind(currentSample,noiseSample)
        }
        outData <- rbind(outData,t(apply(currentSample,1,transformationType)))
    }
    colnames(outData) <- paste0("V",seq(ncol(outData)))
    outList <- list(sampleMatrix=outData,sampleLabels=outLabel,knockoutInfo=knockoutStatus)
    return(outList)
}

simulateExperiment <- function(
                               meanVectorBoundsMatrix, 
                               numSamples=100, 
                               randomSeed=0,
                               transformationList=list(function(x){return(x)},
                                                       function(x){return(x)},
                                                       function(x){return(x)}), 
                               noiseDimension=5,
                               probVecIn, 
                               minSampleSize=5000,
                               maxSampleSize=40000,
                               tncp=10000,
                               knockoutNumber=0, 
                               spikeInFlag=FALSE, 
                               targetRanks=c(length(probVecIn)-1,length(probVecIn)),
                               useBatchFlag=FALSE, 
                               batchEffectShift=0.75,
                               fixedResFlag=FALSE, 
                               responderStatusVec=c(NA)
                               )
{
    probVecForSim <- sort(probVecIn,decreasing=TRUE)
    sampleSpecs <- genClusterCentersWithLabels(
        possibleCenterMat=meanVectorBoundsMatrix,
        nPop=length(probVecForSim),
        seedVal=randomSeed
    )
    currentTransformation <- transformationList[[1]]
    currentSample <- 1
    startKnockoutNum <- numSamples - knockoutNumber + 1
    isKnockoutSample <- FALSE
    regime <- rep(0,numSamples)
    regime[sample(seq(numSamples),(numSamples/2))] <- 1
    if (fixedResFlag) {
        regime <- rep(0,numSamples)
        regime[which(responderStatusVec==1)] <- 1
    }
    nextBatchEffect <- rep((-1*batchEffectShift),ncol(sampleSpecs$fixedMeanMatrix))
    regimeList <- knockoutList <- labelsList <- flowList <- truthList <- list()
    while (currentSample <= numSamples) {
        nextSampleSize <- min(max(minSampleSize,round(rt(1,df=3,ncp=tncp))),maxSampleSize)
        nextRegime <- regime[currentSample]
        if (currentSample >= startKnockoutNum) {
            isKnockoutSample <- TRUE
        }
        else {
            isKnockoutSample <- FALSE
        }
        if ((useBatchFlag) && (((currentSample - 1) %% 10) == 0)) {
            nextBatchEffect <- nextBatchEffect + batchEffectShift
            if ((currentSample - 1) > floor(numSamples/3)) {
                currentTransformation <- transformationList[[2]]
            }
            if ((currentSample - 1) > floor((2*(numSamples/3)))) {
                currentTransformation <- transformationList[[3]]
            }
        }

        sampleData <- simSample(
            sampleDim=ncol(sampleSpecs$fixedMeanMatrix),
            sampleSize=nextSampleSize,
            transformationType=currentTransformation,
            fixedMeanMatrix=sampleSpecs$fixedMeanMatrix,
            fixedLabelVector=sampleSpecs$fixedLabelVector,
            noiseDim=noiseDimension,
            probVecSample=probVecForSim,
            isKnockout=isKnockoutSample,
            isSpikeIn=spikeInFlag,
            sRegime=nextRegime,
            targetRanks=targetRanks,
            hasBatchEffect=useBatchFlag,
            batchEffect=nextBatchEffect
        )
        if (currentSample < 10) {
            outName <- paste0("sample00",currentSample)
        }
        else if (currentSample < 100) {
            outName <- paste0("sample0",currentSample)
        }
        else {
            outName <- paste0("sample",currentSample)
        }
        ff <- flowCore::flowFrame(sampleData$sampleMatrix)
        flowList <- append(flowList,ff)
        names(flowList)[length(flowList)] <- outName
        labelsList <- append(labelsList,list(sampleData$sampleLabels))
        names(labelsList)[length(labelsList)] <- outName
        truthList <- append(truthList,list(table(sampleData$sampleLabels)))
        names(truthList)[length(truthList)] <- outName
        knockoutList <- append(knockoutList,list(table(sampleData$knockoutInfo)))
        names(knockoutList)[length(knockoutList)] <- outName
        regimeList <- append(regimeList,list(nextRegime))
        names(regimeList)[length(regimeList)] <- outName
        currentSample <- currentSample + 1
    }
    truthMat <- getSimTrueCountMatrix(truthList)
    
    outputList <- list(
        "flowFrameList"=flowList,
        "truthValueList"=truthList,
        "truthMat"=truthMat,
        "labelsList"=labelsList,
        "knockoutList"=knockoutList,
        "spikedPop"=sampleSpecs$fixedLabelVector[targetRanks[2]],
        "spikedInPopList"=regimeList
    )
    return(outputList)
}
sampleSize <- 500 
ssLB <- 500 
ssUB <- 500
dataTransformations <- list(function(x){return((x))},
                                function(x){return((x))},
                                function(x){return((x))})
startProb <- 0.1425
refClusterProbVec <- c(
    startProb,rep(startProb/2,2),rep(startProb/4,4),rep(startProb/8,8),rep(startProb/16,16),rep(startProb/32,32),rep(startProb/64,64)
)
numberOfClusters <- 5
clusterProbVec <- sort(refClusterProbVec[seq(numberOfClusters)],decreasing=TRUE)
if (sum(clusterProbVec) < 1) {
    residualPV <- 1-sum(clusterProbVec)
    clusterProbVec <- (clusterProbVec + (residualPV/length(clusterProbVec)))
}
#
#dataset 1 -- make a gating set to illustrate depth-score tuning
#
dimension <- 3
specMat <- matrix(0,nrow=2,ncol=dimension)
specMat[2,] <- c(10,10,1)
simmedExp1 <- simulateExperiment(
    meanVectorBoundsMatrix=specMat,
    numSamples=5,
    transformationList=dataTransformations,
    noiseDimension=0,
    probVecIn=clusterProbVec,
    minSampleSize=ssLB,
    maxSampleSize=ssUB,
    randomSeed=12345,
    tncp=sampleSize
)

specMat[2,] <- c(10,1,1)
simmedExp2 <- simulateExperiment(
    meanVectorBoundsMatrix=specMat,
    numSamples=10,
    transformationList=dataTransformations,
    noiseDimension=0,
    probVecIn=clusterProbVec,
    minSampleSize=ssLB,
    maxSampleSize=ssUB,
    randomSeed=12345,
    tncp=sampleSize
)
ffList <- append(simmedExp1[["flowFrameList"]],
                 simmedExp2[["flowFrameList"]])
names(ffList) <- paste0("Sample_",sprintf('%0.2d', 1:length(ffList)))
fs <- as(ffList, "flowSet")
gs <- flowWorkspace::GatingSet(fs)
```

# Annotation thresholds - depth score tuning

We beging by simulating a simple dataset consisting of 15 samples with three markers, which we generically call `V1`, `V2`, and `V3`.

We invoke the function `generateAnnotationThresholds` on this data set with the following parameter-settings:
- `gatingSet` is passed the GatingSet object loaded in memory.
- `startingCellPop` is the node in the gating hierarchy to analyze. The setting "root" instructs `faust` to use all observations in each sample.
- `projectPath` specifies the location to store the results of the `faust` analysis on disk.
- `plottingDevice` instructs `faust` to generate intermediate diagnostic plots in the `png` format.

```{r at01, message = FALSE, echo=TRUE, eval=FALSE}
#
#generate the annotation thresholds 
#
set.seed(123)
projPath <- file.path(tempdir(),"FAUST")
if (dir.exists(projPath)) {
   unlink(projPath, recursive=TRUE)
}
dir.create(projPath, recursive = TRUE)
generateAnnotationThresholds(
    gatingSet           = gs,
    startingCellPop     = "root",
    projectPath         = projPath,
    plottingDevice      = "png"
)
```
```{r at01a, message = FALSE, echo=FALSE, eval = TRUE, results='hide'}
set.seed(123)
projPath <- file.path(tempdir(),"FAUST")
if (dir.exists(projPath)) {
   unlink(projPath, recursive=TRUE)
}
dir.create(projPath, recursive = TRUE)
invisible(generateAnnotationThresholds(
    gatingSet           = gs,
    startingCellPop     = "root",
    projectPath         = projPath,
    plottingDevice      = "png"
))
```

Once complete, the `faustData` directory will have instantiated a sub-directory called `plotData`. By default, the `faust` function will generate several pdf images in this directory. Here, we investigate the file `scoreLines.png`, which shows thes distribution of depth scores by marker across experimental units in the dataset. 


```{r slp01, echo = FALSE, message=FALSE, fig.align='center', fig.cap='Depth score distribution by marker', out.width='100%', fig.pos='H'}
#
#show the depth score plot
#
knitr::include_graphics(file.path(projPath,"faustData","plotData","scoreLines.png"))
```

Along the x-axis quantiles of the depth score are plotted at increments of `0.01`. The y-axis shows the observed depth-score at this quantile. Each line corresponds to a marker processed in the `faust` analysis.

Inspecting this plot, we see that marker `V1` has a uniformly high depth score, that `V2` has a low depth score for most quantiles and then a jump to high depth score for the higher quanitles, and marker `V3` mainly has low depth score across all quantiles.

The solidly-colored line of `V1` indicates that `faust` has selected this marker for the phenotype discovery in the latter phase of the analysis. The dashed lines for markers `V2` and `V3` indcates `faust` has removed these markers from the phenotype discovery phase based on the default parameter settings. The two dashed red lines also appear on the plot: the vertical red line corresponds to the parameter `selectionQuantile` and the horizontal line to the parameter `depthScoreThreshold`. By default, these parameters are set to 0.50 and 0.01 respectively, and define the default marker selection policy of `faust`: all markers with empirical depth score above the `depthScoreThreshold` at the specified `selectionQuantile` will be included for phenotype discovery; those markers below the threshold, excluded.

This distribution of scores can be connected to the underlying data. For `V1`, we expect that univariate multimodality should be visible across the experiment because the depth score is uniformly high. For `V2` we expect multimodality to be visible only in a subset of samples. And for `V3` we expect univarite plots to show no discernable multimodality.

The following ridgelines confirm this expectation.

```{r sr01, message=FALSE, eval=TRUE, echo=TRUE, out.width = 8, out.height = 8}
#, results='asis'}
#
#link the scoreLines plot to the sample-level data
#
all_samples <- list.files(file.path(projPath,"faustData","sampleData"))
firstSample <- TRUE
for (sn in all_samples) {
    sample_data <- as.data.frame(readRDS(file.path(projPath,"faustData","sampleData",sn,"exprsMat.rds")))
    sample_data$`sample_id` <- sn
    if (firstSample) {
        all_sample_data <- sample_data
        firstSample <- FALSE
    }
    else {
        all_sample_data <- rbind(all_sample_data,sample_data)
    }
}
depth_score_demo_df <- gather(all_sample_data,key="Marker",value="Expression",-sample_id)
p1 <- ggplot(depth_score_demo_df, aes(x = Expression, y = sample_id,fill=Marker))+
    facet_wrap(~Marker,ncol=2)+
    geom_density_ridges(rel_min_height=0.01)+
    theme_ridges(center_axis_label=TRUE)+
    ylab("Simulated sample")+
    xlab("Simulated expression")+
    theme(axis.text.x=element_blank(),
          axis.ticks.x=element_blank(),
          axis.text.y=element_blank(),
          axis.ticks.y=element_blank(),
          legend.position="bottom")
p1
```

This presents the first tuning opportunity for `faust`: we see that for 5 of the simulated samples, marker `V2` has clear evidence of multimodality. Should it be included in the analysis?

The decision to tune `faust` to include markers based on the depth score is informed by the experimental design. Imagine, for example, that these simulated samples came from a an experiment with five subjects and three stimulation conditions: control, stim1, and stim2. It is possible that multimodality (corresponding to expression of the marker) is expected only in a subset of samples based on such a design. It may then be desirable to tune `faust` to include marker `V2` in such a case: while we do not know if the curve observed for marker `V2` corresponds to a specific stimulation condition, this trend line (arising from the data) may be consistent with our prior beliefs about the experimental context.

We show how to perform this tuning in the following code chunk. In addition to the original parameter settings we now set:
- `depthScoreThreshold` to a value above its default of 0.01.
- `selectionQuantile` to a quantile setting above its default of 0.50.

These updated settings are based off our inspection of the intermediate `scoreLines` plot.

```{r at02, echo=TRUE, eval = FALSE}
#
#re-run tuning the depth score selection criteria
#
projPath02 <- file.path(tempdir(),"FAUST_R2")
if (dir.exists(projPath02)) {
   unlink(projPath02, recursive=TRUE)
}
dir.create(projPath02, recursive = TRUE)
generateAnnotationThresholds(
    gatingSet           = gs,
    startingCellPop     = "root",
    projectPath         = projPath02,
    depthScoreThreshold = 0.25,
    selectionQuantile   = 0.825,
    plottingDevice      = "png"
)
```
```{r at02a, message = FALSE, echo=FALSE, eval = TRUE, results='hide'}
#
#re-run tuning the depth score selection criteria
#
projPath02 <- file.path(tempdir(),"FAUST_R2")
if (dir.exists(projPath02)) {
   unlink(projPath02, recursive=TRUE)
}
dir.create(projPath02, recursive = TRUE)
invisible(generateAnnotationThresholds(
    gatingSet           = gs,
    startingCellPop     = "root",
    projectPath         = projPath02,
    depthScoreThreshold = 0.25,
    selectionQuantile   = 0.825,
    plottingDevice      = "png"
))
```

Note we unlink the `faustData` directory prior to re-running. We recommend doing this on re-run. Once we have re-run, we again inspect the depth score plot, and see that both `V1` and `V2` are now included.

```{r slp02, echo = FALSE, message=FALSE, fig.align='center', fig.cap='Depth score distribution by marker', out.width='100%', fig.pos='H'}
#
#show the depth score plot
#
knitr::include_graphics(file.path(projPath02,"faustData","plotData","scoreLines.png"))
```

If possible, we recommend discussing the experimental design with the scientist(s) that generated the dataset (if different from the person reading this vignette) prior to applying `faust` to the dataset, in order to understand what design parameters might influence the `faust` analysis. In addition to stimulation conditions, other information that may be useful to describe to `faust` is information about time points in longitudinal studies, if specific markers in the panel are included because they are required to answer a question of scientific interest, if there are known batch effects, and if prior biological knowledge leads to expected characteristics about the dataset. 

One final comment: we do not recommend including external metadata that will be used in follow-on modeling in the `faust` analysis. For example, if a cytometry experiment is designed to discover phenotypes that differentiating subjects that respond to therapy from those that do not, the responder status of individual subjects should be held-out from `faust` to prevent biasing the follow-on analysis. This same comment potentially applies to any external metadata (including meta data describing stimulation condtions, etc), and so tuning requires consideration on an experiment-by-experiment basis.

# Annotation thresholds - tuning the experimental unit

Continuing with the previous example, let's suppose that the 15 that these simulated samples did come from a an experiment with five subjects and three stimulation conditions: control, stim1, and stim2. When we are aware of such a design, we often wish to set the experimental unit to `subject` rather than the default of a `sample`, in order to have a per-subject annotation thresholds against which changes in abundance due to stimulation conditions may be detected.

To tune `faust` to do this, all levels of the experimental unit must be stored in the `pData` of the `GatingSet`. The name of the variable in the `pData` is then passed to the `faust` function in order to use that grouping as the experimental unit. 

```{r pdata_update, echo=TRUE, eval = TRUE}
pd <- pData(gs)
pd$subject <- rep(paste0("Subject_",seq(5)),3)
pData(gs) <- pd
kable(pData(gs), caption = "Meta data stored in the GatingSet pData")
```

Examining the pData, we see that the mapping from sample to subject is now stored in the GatingSet. We next invoke `generateAnnotationThresholds`, tuned to use the subject as the experimental unit.

```{r at03, echo=TRUE, eval = FALSE}
#
#re-run tuning the depth score selection criteria
#
projPath03 <- file.path(tempdir(),"FAUST_R3")
if (dir.exists(projPath03)) {
   unlink(projPath03, recursive=TRUE)
}
dir.create(projPath03, recursive = TRUE)
generateAnnotationThresholds(
    gatingSet           = gs,
    startingCellPop     = "root",
    projectPath         = projPath03,
    depthScoreThreshold = 0.25,
    selectionQuantile   = 0.825,
    plottingDevice      = "png",
    experimentalUnit    = "subject"
)
```
```{r at03a, message = FALSE, echo=FALSE, eval = TRUE, results='hide'}
#
#re-run tuning the depth score selection criteria
#
projPath03 <- file.path(tempdir(),"FAUST_R3")
if (dir.exists(projPath03)) {
   unlink(projPath03, recursive=TRUE)
}
dir.create(projPath03, recursive = TRUE)
invisible(generateAnnotationThresholds(
    gatingSet           = gs,
    startingCellPop     = "root",
    projectPath         = projPath03,
    depthScoreThreshold = 0.25,
    selectionQuantile   = 0.825,
    plottingDevice      = "png",
    experimentalUnit    = "subject"
))
```

We again look at the depth score plot in the following display.

```{r slp03, echo = FALSE, message=FALSE, fig.align='center', fig.cap='Depth score distribution by marker', out.width='100%', fig.pos='H'}
#
#show the depth score plot
#
knitr::include_graphics(file.path(projPath03,"faustData","plotData","scoreLines.png"))
```

When we look at the depth score plot, we now see that markers `V1` and `V2` have consistent depth score across the experiment. This is because by concatenating expression data by subject, marker V2 now consistently appears to have multimodality across the expeirment. This can be confirmed by viewing the expression data for the experimental unit.